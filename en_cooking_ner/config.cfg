[paths]
train = null
dev = null
vectors = null
init_tok2vec = null

[system]
seed = 0
gpu_allocator = null

[nlp]
lang = "en"
pipeline = ["llm"]
disabled = []
before_creation = null
after_creation = null
after_pipeline_creation = null
batch_size = 1000
tokenizer = {"@tokenizers":"spacy.Tokenizer.v1"}
vectors = {"@vectors":"spacy.Vectors.v1"}

[components]

[components.llm]
factory = "llm"
save_io = true
validate_types = true

[components.llm.cache]
@llm_misc = "spacy.BatchCache.v1"
path = null
batch_size = 64
max_batches_in_mem = 4

[components.llm.model]
@llm_models = "spacy.GPT-3-5.v1"
name = "gpt-3.5-turbo"
strict = true
max_tries = 5
interval = 1.0
max_request_time = 30
endpoint = null

[components.llm.model.config]
temperature = 0.3

[components.llm.task]
@llm_tasks = "spacy.NER.v2"
labels = ["DISH","INGREDIENT","EQUIPMENT"]
parse_responses = null
prompt_example_type = null
template = "You are an expert Named Entity Recognition (NER) system. Your task is to accept Text as input and extract named entities for the set of predefined entity labels.\nFrom the Text input provided, extract named entities for each label in the following format:\n{# whitespace #}\n{# whitespace #}\n{%- for label in labels -%}\n{{ label }}: <comma delimited list of strings>\n{# whitespace #}\n{%- endfor -%}\n{# whitespace #}\n{# whitespace #}\n{%- if label_definitions -%}\nBelow are definitions of each label to help aid you in what kinds of named entities to extract for each label.\nAssume these definitions are written by an expert and follow them closely.\n{# whitespace #}\n{# whitespace #}\n{%- for label, definition in label_definitions.items() -%}\n{{ label }}: {{ definition }}\n{# whitespace #}\n{%- endfor -%}\n{# whitespace #}\n{# whitespace #}\n{%- endif -%}\n{# whitespace #}\n{# whitespace #}\n{%- if prompt_examples -%}\nBelow are some examples (only use these as a guide):\n{# whitespace #}\n{# whitespace #}\n{%- for example in prompt_examples -%}\nText:\n'''\n{{ example.text }}\n'''\n{# whitespace #}\n{%- for label, substrings in example.entities.items() -%}\n{# whitespace #}\n{{ label }}: {{ ', '.join(substrings) }}\n{%- endfor -%}\n{# whitespace #}\n{# whitespace #}\n{# whitespace #}\n{%- endfor -%}\n{# whitespace #}\n{# whitespace #}\n{%- endif -%}\nHere is the text that needs labeling:\n{# whitespace #}\nText:\n'''\n{{ text }}\n'''\n"
label_definitions = null
examples = null
normalizer = null
alignment_mode = "contract"
case_sensitive_matching = false
single_match = false
scorer = null

[corpora]

[corpora.dev]
@readers = "spacy.Corpus.v1"
path = ${paths.dev}
gold_preproc = false
max_length = 0
limit = 0
augmenter = null

[corpora.train]
@readers = "spacy.Corpus.v1"
path = ${paths.train}
gold_preproc = false
max_length = 0
limit = 0
augmenter = null

[training]
seed = ${system.seed}
gpu_allocator = ${system.gpu_allocator}
dropout = 0.1
accumulate_gradient = 1
patience = 1600
max_epochs = 0
max_steps = 20000
eval_frequency = 200
frozen_components = []
annotating_components = []
dev_corpus = "corpora.dev"
train_corpus = "corpora.train"
before_to_disk = null
before_update = null

[training.batcher]
@batchers = "spacy.batch_by_words.v1"
discard_oversize = false
tolerance = 0.2
get_length = null

[training.batcher.size]
@schedules = "compounding.v1"
start = 100
stop = 1000
compound = 1.001
t = 0.0

[training.logger]
@loggers = "spacy.ConsoleLogger.v1"
progress_bar = false

[training.optimizer]
@optimizers = "Adam.v1"
beta1 = 0.9
beta2 = 0.999
L2_is_weight_decay = true
L2 = 0.01
grad_clip = 1.0
use_averages = false
eps = 0.00000001
learn_rate = 0.001

[training.score_weights]

[pretraining]

[initialize]
vectors = ${paths.vectors}
init_tok2vec = ${paths.init_tok2vec}
vocab_data = null
lookups = null
before_init = null
after_init = null

[initialize.components]

[initialize.tokenizer]